[id="creating-a-telemetry-plugin_{context}"]
= Creating A Telemetry Plug-in

This section shows how to create an `AnalyticsManager` class that extends link:https://github.com/che-incubator/che-workspace-telemetry-client/blob/master/backend-base/src/main/java/org/eclipse/che/incubator/workspace/telemetry/base/AbstractAnalyticsManager.java[`AbstractAnalyticsManager`] and implements the following methods:

* `isEnabled()` - determines whether the telemetry back-end is functioning correctly. This could mean always returning `true`, or have more complex checks, for example, returning `false` when a connection property is missing.
* `destroy()` - cleanup method that is run before shutting down the telemetry back-end. This method sends the `WORKSPACE_STOPPED` event.
* `onActivity()` - notifies that some activity is still happening for a given user. This is mainly used to send `WORKSPACE_INACTIVE` events.
* `onEvent()` - submits telemetry events to the telemetry server, such as `WORKSPACE_USED` or `WORKSPACE_STARTED`.
* `increaseDuration()` - increases the duration of a current event rather than sending many events in a small frame of time.

The following sections cover:

* Creation of a telemetry server to echo events to standard output.
* Extending the {prod-short} telemetry client and implementing a user's custom back-end.
* Creating a `plugin.yaml` file representing a {prod-short} workspace plug-in for a user's custom back-end.
* Specifying of a location of a custom plug-in to {prod-short} by setting the `workspacesDefaultPlugins` attribute from the `CheCluster` custom resource.

== Getting Started

This document describes the steps required to extend the {prod-short} telemetry system to connect to a custom back-end:

. Creating a server process that receives events
. Extending {prod-short} libraries to create a back-end that send events to the server
. Packaging the telemetry back-end in a container and deploying it to an image registry
. Adding a plug-in for your back-end and instructing {prod-short} to load the plug-in in your {devworkspace}s

A finished example of the telemetry back-end is available here.

[discrete]
== Creating a server that receives events

For demonstration purposes, this example shows how to create a server that receives events from our telemetry plug-in and writes them to standard output.

For production use cases, consider integrating with a third-party telemetry system (for example, Segment, Woopra) rather than creating your own telemetry server. In this case, use your provider's APIs to send events from your custom back-end to their system.

The following Go code starts a server on port 8080 and writes events to standard output:

.`main.go`
====
[source,go]
----
include::example$telemetry/main.go[]
----
====

Create a container image based on this code and expose it as a deployment in OpenShift in the {prod-namespace} {orch-namespace}. The code for the example telemetry server is available at link:https://github.com/che-incubator/che-workspace-telemetry-example[che-workspace-telemetry-example]. To deploy the telemetry server, clone the repository and build the container:

----
$ git clone https://github.com/che-incubator/che-workspace-telemetry-example
$ cd che-workspace-telemetry-example
$ docker build -t registry/organization/che-workspace-telemetry-example:latest .
$ docker push registry/organization/che-workspace-telemetry-example:latest
----

In `manifest.yaml`, replace the `image` and `host` fields to match the image you pushed, and the public hostname of your {platforms-name} cluster. Then run:

[subs="+quotes"]
----
$ kubectl apply -f manifest.yaml -n {prod-namespace}
----

== Creating a new Maven project

NOTE: For fast feedback when developing, it is recommended to do development inside a {prod-short} workspace. This way, you can run the application in a cluster and connect to the workspaces front-end telemetry plug-in to send events to your custom back-end.

pass:[<!-- vale RedHat.TermsErrors = NO -->]

. Create a new Maven Quarkus project scaffolding:
+
----
$ mvn io.quarkus:quarkus-maven-plugin:2.7.1.Final:create \
  -DprojectGroupId=mygroup -DprojectArtifactId=telemetryback-end \
  -DprojectVersion=my-version -DclassName="org.my.group.MyResource"
----

pass:[<!-- vale RedHat.TermsErrors = YES -->]

. Add the following dependencies to your `pom.xml`:
+
.`pom.xml`
====
[source,xml]
----
include::example$telemetry/pom_snippet.xml[]
----
====

. Consult the link:https://github.com/che-incubator/che-workspace-telemetry-client/packages[GitHub packages] for the latest version and Maven coordinates of `backend-base`. link:https://help.github.com/en/packages/publishing-and-managing-packages/about-github-packages[GitHub packages] require a personal access token with `read:packages` permissions to download the {prod-short} telemetry libraries. Create a personal access token and copy the token value.

. Add the coordinates and token to the `che-incubator` packages in your `~/.m2/settings.xml` file:
+
.`settings.xml`
====
[source,xml]
----
include::example$telemetry/settings.xml[]
----
====
+

[id="running-the-application_{context}"]
== Running the application

Run and test the application is in a {devworkspace}:

----
$ mvn quarkus:dev -Dquarkus.http.port=${DEVWORKSPACE_TELEMETRY_BACKEND_PORT}
----

If {prod-short} is secured using a self-signed certificate, add the certificate to a trust store and mount it into the workspace. Also add the Java system property, `-Djavax.net.ssl.trustStore=/path/to/trustStore`, to the `mvn` command. For example, assuming the trust store is located in `$JAVA_HOME/jre/lib/security/cacerts`:

[subs="+quotes"]
----
$ keytool -import -alias self-signed-certificate \
  -file _<path/to/self-signed-certificate>_ -keystore $JAVA_HOME/jre/lib/security/cacerts
----

Followed by:

----
$ mvn quarkus:dev -Dquarkus.http.port=${CHE_WORKSPACE_TELEMETRY_BACKEND_PORT} \
  -Djavax.net.ssl.trustStore=$JAVA_HOME/jre/lib/security/cacerts
----

== Creating a concrete implementation of AnalyticsManager and adding specialized logic

Create two new files in your project:

* `AnalyticsManager.java` - contains the logic specific to the telemetry system.
* `MainConfiguration.java` - contains configuration provided to `AnalyticsManager`.

.`AnalyticsManager.java`
====
[source,java]
----
include::example$telemetry/AnalyticsManagerSkeleton.java[]
----
====

.`MainConfiguration.java`
====
[source,java]
----
include::example$telemetry/MainConfiguration.java[]
----
====
<1> A MicroProfile configuration annotation is used to inject the `welcome.message` configuration.
<2> Declaring an optional configuration

For more details on how to provide configuration properties specific to your back-end, see the Quarkus link:https://quarkus.io/guides/config-reference[Configuration Reference Guide].


.`application.properties`
====
[source,properties]
----
include::example$telemetry/application.properties[]
----
====


Since `org.my.group.AnalyticsManager` and `org.my.group.MainConfiguration` are alternative beans, specify them using the `quarkus.arc.selected-alternatives` property in `src/main/resources/application.properties`.


== Implementing `isEnabled()`

For the purposes of the example, this method just returns `true` whenever it is called. Whenever the server is running, it is enabled and operational.

.`AnalyticsManager.java`
====
[source,java]
----
include::example$telemetry/isEnabled.java[]
----
====

It is possible to put more complex logic in `isEnabled()`. For example, the link:https://github.com/che-incubator/devworkspace-telemetry-woopra-plugin/blob/main/src/main/java/com/redhat/devworkspace/services/telemetry/woopra/AnalyticsManager.java[hosted {prod-short} woopra back-end] checks that a configuration property exists before determining if the back-end is enabled.

== Implementing `onEvent()`

`onEvent()` sends the event received by the back-end to the telemetry system. For the example application, it sends an HTTP POST payload to the `/event` endpoint from the telemetry server.

=== Sending a POST request to the example telemetry server
For the following example, the telemetry server application is deployed to OpenShift at the following URL: `++http://little-telemetry-server-che.apps-crc.testing++`.

. Set up the RESTEasy REST Client by creating `TelemetryService.java`

+
.`TelemetryService.java`
====
[source,java]
----
include::example$telemetry/TelemetryService.java[]
----
====
<1> The endpoint to make the `POST` request to.
+

. Specify the base URL for `TelemetryService` in the `application.properties` file

+
.`application.properties`
====
[source,properties]
----
include::example$telemetry/rest-client.properties[]
----
====
+

. Inject `TelemetryService` into `AnalyticsManager` and send a `POST` request in `onEvent()`

+
.`AnalyticsManager.java`
====
[source,java]
----
include::example$telemetry/onEvent.java[]
----
====
+

This sends an HTTP request to the telemetry server and automatically delays identical events for a small period of time. The default duration is 1500 milliseconds. You can modify the duration by setting subclasses.

== Implementing `increaseDuration()`

Many telemetry systems recognize event duration. The `AbstractAnalyticsManager` merges similar events that happen in the same frame of time into one event. This implementation of `increaseDuration()` is a no-op. This method uses the APIs of the user's telemetry provider to alter the event or event properties to reflect the increased duration of an event.

.`AnalyticsManager.java`
====
[source,java]
----
include::example$telemetry/increaseDuration.java[]
----
====

== Implementing `onActivity()`

Set an inactive timeout limit, and use `onActivity()` to send a `WORKSPACE_INACTIVE` event if the last event time is longer than the inactivity timeout.

.`AnalyticsManager.java`
====
[source,java]
----
include::example$telemetry/onActivity.java[]
----
====

== Implementing `destroy()`

When `destroy()` is called, send a `WORKSPACE_STOPPED` event and shutdown any resources, such as connection pools.

.`AnalyticsManager.java`
====
[source,java]
----
include::example$telemetry/destroy.java[]
----
====

Running `mvn quarkus:dev` as described in xref:running-the-application_{context}[] displays the `WORKSPACE_STOPPED` event, sent to the server when the Quarkus application is terminated.

== Packaging the Quarkus application

See link:https://quarkus.io/guides/building-native-image#using-a-multi-stage-docker-build[the Quarkus documentation] for the best instructions to package the application in a container. Build and push the container to a container registry of your choice.

==== Sample Dockerfile used to build a Quarkus image running with JVM

.`Dockerfile.jvm`
====
[source,yaml]
----
include::example$telemetry/Dockerfile.jvm[]
----
====
To build the image, run:
----
./mvnw package && \
docker build -f src/main/docker/Dockerfile.jvm -t image:tag .
----

==== Sample Dockerfile for Quarkus native image

.`Dockerfile.native`
====
[source,yaml]
----
include::example$telemetry/Dockerfile.native[]
----
====
To build the image, run:
----
./mvnw package -Pnative -Dquarkus.native.container-build=true && \
docker build -f src/main/docker/Dockerfile.native -t image:tag .
----

== Creating a `plugin.yaml` for your plug-in

Create a `plugin.yaml` devfile v2 file representing a {devworkspace} plug-in that runs your custom back-end in a workspace Pod. For more information about devfile v2, see link:https://devfile.io/docs/[Devfile v2 documentation]

.`plugin.yaml`
====
[source,yaml]
----
include::example$telemetry/sample_plugin.yaml[]
----
====

<1> Specify the container image built from here

Typically, the user deploys this file to a corporate web server. This guide demonstrates how to create an Apache web server on OpenShift and host the plug-in there.

Create a ConfigMap referencing the new `plugin.yaml` file.

[subs="+attributes"]
----
$ oc create configmap --from-file=plugin.yaml -n {prod-namespace} telemetry-plugin-meta
----

Create a deployment, a service, and a route to expose the web server. The deployment references this ConfigMap and places it in the `/var/www/html` directory.

.`manifests.yaml`
====
[source,yaml,subs="+quotes,+attributes"]
----
include::example$telemetry/webserver.yaml[]
----
====

----
$ oc apply -f manifests.yaml
----

.Verification steps

After the deployment has started to start, confirm that `plugin.yaml` is available in the web server:

----
$ curl apache-che.apps-crc.testing/plugin.yaml
----

This command should return the `plugin.yaml` file.


== Running the telemetry plug-in in a {devworkspace}
. Create a new {devworkspace}
. Add the following to the `components` field:

+
----
components:
  ...
  - name: telemetry-plugin
    plugin:
      uri: apache-che.apps-crc.testing/plugin.yaml
----
+

. Start the {devworkspace} from the {prod} dashboard.

== Starting the telemetry plug-in for all {devworkspace}s

Set the telemetry plug-in as a default plug-in in the `spec.server.workspaceDefaultPlugins` field for the `CheCluster` custom resource. Default plug-ins are applied on {devworkspace} startup for new and existing {devworkspace}s.
----
spec:
  ...
  server:
    ...
    workspacesDefaultPlugins:
    - editor: eclipse/che-theia/next              <1>
      plugins:                                    <2>
      - 'apache-che.apps-crc.testing/plugin.yaml'
----

<1> The editorId to set default plug-ins for
<2> List of URLs to devfile v2 plug-ins

This can be accomplished by running `oc edit checluster -n {prod-namespace}` and typing in the change at the terminal, or by editing the CR in the OpenShift console (*Installed Operators -> {prod} -> {prod} Cluster -> {prod-checluster} -> YAML*).

For more information about the Che Cluster custom resource, see
xref:installation-guide:understanding-the-checluster-custom-resource.adoc[].

.Verification steps

. Start a new {devworkspace} from the {prod} dashboard.


// After saving the changes,  . See a new message stating that the plug-in is being installed into the workspace.

// image::telemetry/custom_telemetry_plugin.png[Custom telemetry plug-in]

// Perform any operations in the started workspace and observe their events in the example telemetry server logs.
